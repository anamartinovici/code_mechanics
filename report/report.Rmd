---
title             : "EEG Many Pipelines - Code Mechanics"
shorttitle        : "Code Mechanics"
author:
  - name          : "Sebastian Speer"
    affiliation   : "1"
  - name          : "Antonio Schettino"
    affiliation   : "2,3"
  - name          : "Ana Martinovici"
    affiliation   : "4"
    corresponding : yes # only one corresponding author
    address       : "Burgemeester Oudlaan 50, 3062 PA Rotterdam, Netherlands"
    email         : "martinovici@rsm.nl"
affiliation:
  - id            : "1"
    institution   : "Social Brain Lab, Netherlands Institute for Neuroscience, Amsterdam, The Netherlands"
  - id            : "2"
    institution   : "Erasmus Research Services, Erasmus University Rotterdam, Rotterdam, The Netherlands"    
  - id            : "3"
    institution   : "Institute for Globally Distributed Open Research and Education (IGDORE), Sweden"
  - id            : "4"
    institution   : "Rotterdam School or Management, Erasmus University Rotterdam, Rotterdam, The Netherlands"
authornote: |
  Authorship order was randomly determined via the `sample` function in *R*. 
  
  **SS** preprocessed the data and performed time-frequency analysis (research questions 2b, 2c, 3b, 4b). **AS** preprocessed the data and performed ERP analysis (research questions 1, 2a, 3a, 4a). **AM** was responsible for project management, GitHub repository, and reproducibility. **SS**, **AS**, and **AM** wrote the report.
abstract: |
  <!-- https://tinyurl.com/ybremelq -->
  
  One or two sentences providing a **basic introduction** to the field, comprehensible to a scientist in any discipline.
  
  Two to three sentences of **more detailed background**, comprehensible to scientists in related disciplines.
  
  One sentence clearly stating the **general problem** being addressed by this particular study.
  
  One sentence summarizing the main result (with the words "**here we show**" or their equivalent).
  
  Two or three sentences explaining what the **main result** reveals in direct comparison to what was thought to be the case previously, or how the main result adds to previous knowledge.
  
  One or two sentences to put the results into a more **general context**.
  
  Two or three sentences to provide a **broader perspective**, readily comprehensible to a scientist in any discipline.

keywords          : ["EEG Many Pipelines", "scene categorization", "vision", "EEG", "ERP", "time-frequency analysis", "Bayesian multilevel linear regression", "TFCE"]
wordcount         : "X" # to be added when the report is completed 
bibliography      : "references.bib"
link-citations    : true # create hyperlink to the corresponding bibliography entry
zotero            : "EEGManyPipelines_CodeMechanics" # Zotero group library 
floatsintext      : yes # place figures and tables in the text rather than at the end?
linenumbers       : no # add line numbers in the margins?
draft             : no # add “DRAFT” watermark to every page?
mask              : no # omit identifying information from the title page?
figurelist        : no # list of figure captions after the reference section?
tablelist         : no # list of table captions after the reference section?
footnotelist      : no # list of footnotes after the reference section?
numbersections    : yes # are section headers numbered? 
classoption       : "man" # option "doc" produces a non-APA-formatted document (single-spaced, single-column)
output: 
  papaja::apa6_pdf:
    keep_tex: FALSE # delete the LaTeX source file after the PDF has been rendered
editor_options: 
  chunk_output_type: console
---

```{r install-latex, include = FALSE, eval = FALSE}

# if LaTeX is not installed:
install.packages("tinytex")
library("tinytex")
tinytex::install_tinytex()

```

```{r install-packages, include = FALSE, eval = FALSE}

install.packages("here")
devtools::install_github("crsh/papaja")

```

```{r setup, include = FALSE}

# load packages
library("here")
library("papaja")

# knitr global chunk options
knitr::opts_chunk$set(
	out.width = '90%' # plot size in the output document
	)

# set seed for random number generation
seed_project <- 999
set.seed(seed_project)

```

```{r authorship-order, include = FALSE, eval = FALSE}

# procedure used to determine authorship order
authors <- c("Ana Martinovici", "Antonio Schettino", "Sebastian Speer") # initial order is alphabetical
authorship_order <- sample(authors)

authorship_order

```

# Introduction

Timeline of our contribution to the EEGManyPipelines project:

-   we registered for the EEGManyPipelines project on 2021-09-15, and received the confirmation email 2021-09-20.

-   instructions for downloading the data and for analysis were sent 2021-10-08. These are saved within the repository at `data_in_repo/original_data/instructions`.

-   we received the link to the submission portal on 2022-05-02

-   we've submitted the pre-processed data on

# Methods

## Preprocessing

### ERP

For each participant, the continuous EEG data was assigned electrode coordinates and filtered with two consecutive Hamming windowed sinc FIR filters (high-pass 0.1 Hz, low-pass 40 Hz). Bad or noisy channels were detected using several approaches implemented in the PREP pipeline [@bigdely-shamlo2015], including flat or missing signal, "bad-by-high-frequency-noise" (frequency components above 50 Hz considerably higher than median channel noisiness, as calculated using a robust *Z*-scoring method and default threshold *z* \> 5), "bad-by-correlation" (maximum correlation with another channel below the default *r* = .4; fraction of bad correlation windows above the default threshold of 0.01), "bad-by-deviation" (amplitude deviates from the median channel amplitude, as calculated using a robust *Z*-scoring method and default threshold *z* \> 5), and signal prediction based on signals and spatial locations of other channels lower than default threshold of *r* = .75 (random sample consensus approach, *RANSAC*; @fischler1987).[^1] Channels identified as noisy were removed from the data and subsequently interpolated via a spherical spline procedure [@perrin1989].\

[^1]: For more details, see the documentation of [`NoisyChannels`](https://pyprep.readthedocs.io/en/latest/generated/pyprep.NoisyChannels.html#pyprep.NoisyChannels).

Afterwards, the EEG data were re-referenced to the average signal across channels. Ocular artifacts were then corrected by means of independent component analysis via the `picard` algorithm [@ablin2018] and the resulting components were correlated with activity recorded from the EOG channels, in order to identify which components best represented horizontal eye movements and blinks. The components that correlated the highest with the EOG channels were then removed from the EEG data before re-conversion into channel space.\
The EEG data was subsampled by a factor of four (i.e., from 512 Hz to 128 Hz) and segmented into epochs extending from -200ms to +500ms time-locked to scene onset, and baseline correction was applied using the pre-stimulus interval. The epoched data was then subjected to *Autoreject*, an automated artifact detection algorithm based on machine-learning classifiers and cross-validation to estimate the optimal peak-to-peak threshold [@jas2017]. This algorithm was implemented to remove artifacts not identified by previous preprocessing steps and, depending on the number of bad sensors for a given trial, either repairs the trial based on spherical spline interpolation or excludes it from further analysis.[^2]\

[^2]: For more details, see the documentation of [`autoreject`](https://autoreject.github.io/stable/index.html).

### TFR

Signal preprocessing for time-frequency analysis followed a similar procedure, with the following exceptions: (*i*) high-pass filter cut-off 1 Hz; (*ii*) continuous data segmented into 800 ms epochs (-300ms to +500ms time-locked to scene onset) and baseline corrected using the pre-stimulus interval.\
The preprocessed data were then submitted to a Morlet wavelet analysis to transform the data into the time-frequency domain with 18 log-scaled frequency bins ranging from 4 to 40 Hz, to increase sensitivity at lower frequency ranges. To optimize both spectral and temporal resolution, the number of cycles to include in the sliding time window were defined by dividing each individual frequency by two. After transforming the data to the time-frequency domain, the data were decimated by a factor of two (sampling every second time point) to increase computational efficiency.

### Epoching

The clean epoched data were separated into 8 conditions to investigate each research question:

-   **RQ1**
    1.  *manmade*: scenes categorized as `man-made`, presented for the first time or previously (`new` and `old`), subsequently remembered or forgotten (`subsequent_remembered` and `subsequent_forgotten`), excluding `NA` in behavioral responses (although scene category is independent from response, `NA` may reflect drops in attention and, consequently, incomplete stimulus perception)
    2.  *natural*: scenes categorized as `natural`, `new` and `old`, `subsequent_remembered` and `subsequent_forgotten`, excluding `NA` in behavior
-   **RQ2**
    3.  *new*: `man-made` and `natural` scenes, presented for the first time (`new`), `subsequent_remembered` and `subsequent_forgotten`, excluding `NA` in behavior
    4.  *old*: `man-made` and `natural` scenes, presented previously (`old`), `subsequent_remembered` and `subsequent_forgotten`, excluding `NA` in behavior
-   **RQ3**
    5.  *old-hit*: `man-made` and `natural` scenes, presented previously (`old`), successfully recognized as such (`hit`), can include `NA` in memory (the image has been successfully categorized as old, regardless of whether it is recognized as such in subsequent presentations)
    6.  *old-miss*: `man-made` and `natural` scenes, presented previously (`old`), not recognized as such (`miss`), can include `NA` in memory
-   **RQ4**
    7.  *remembered*: `man-made` and `natural` scenes, `new` and `old`, `subsequent_remembered`, include all behavior
    8.  *forgotten*: `man-made` and `natural` scenes, `new` and `old`, `subsequent_forgotten`, include all behavior

# Analysis

## RQ1

We were asked to test the following:

> *RQ1. There is an effect of scene category (i.e., a difference between images showing man-made vs. natural environments) on the amplitude of the N1 component, i.e. the first major negative EEG voltage deflection.*

To address this question, we identified the N1 ERP component by visually inspecting topographies and waveforms of the grand-average signal (i.e., collapsed across all participants and both *man-made* and *natural* conditions). This unbiased *collapsed localizer* approach [@Luck2017, p. 150] revealed a negative deflection at a region of interest (*ROI*) comprising electrodes *PO7*, *PO3*, *O1*, *PO4*, *PO8*, and *O2* (see Figure \@ref(fig:figure01)), and a time window between 130 - 180 ms after stimulus onset (see Figure \@ref(fig:figure02)).\

(ref:figure01-caption) Collapsed localizer (i.e., amplitude averaged across *manmade* and *natural* conditions between 130 - 180 ms after stimulus onset) used to identify the electrodes best representing the expected topography of the N1 ERP component (*PO7*, *PO3*, *O1*, *PO4*, *PO8*, *O2*).

```{r figure01, fig.cap = "(ref:figure01-caption)"}

knitr::include_graphics(here("results_in_repo/RQ1/topo_grand_average_ROI.png"))

```

(ref:figure02-caption) Collapsed localizer (i.e., amplitude averaged across *manmade* and *natural* conditions at electrodes *PO7*, *PO3*, *O1*, *PO4*, *PO8*, *O2*) used to identify the time window of the N1 ERP component between 130 - 180 ms after stimulus onset (red box).

```{r figure02, fig.cap = "(ref:figure02-caption)"}

knitr::include_graphics(here("results_in_repo/RQ1/timeseries_grand_average_ROI.png"))

```

Participant- and condition-specific N1 amplitude was extracted by averaging values recorded at this ROI and time window (see Figure \@ref(fig:figure03)).\

(ref:figure03-caption) Raincloud plot [@allen2021] showing trial-averaged N1 amplitude values -- extracted from the electrode ROI and time window identified via visual inspection of the collapsed localizer --, separately for each participant and condition.

```{r figure03, fig.cap = "(ref:figure03-caption)"}

knitr::include_graphics(here("results_in_repo/RQ1/raincloud_ERP_avg_trials_informative_prior.png"))

```

Subsequently, we fit a Bayesian multilevel linear model on N1 amplitude values, with *condition* (2 levels: *man-made*, *natural*) as *constant* (a.k.a. fixed) effect and participant and trial as *varying* (a.k.a. random) effects. We allowed intercepts and slopes to vary as a function of participant and trials, to model general and condition-specific inter-individual differences. As likelihood function, we chose a Gaussian distribution.\
An important aspect of Bayesian analysis is the choice of priors [e.g., @natarajan2000]. Given the susceptibility of the electrophysiological signal to inter-individual differences (e.g., skull thickness, skin conductance, or hair), we decided to base our priors on the current data by visually inspecting the *collapsed localizer* (see above). For the main analysis, we placed **informative priors** on the *intercept* -- a normal distribution with mean $\mu$ = 4 and standard deviation $\sigma$ = 2: $Normal(4,2)$ -- and $\beta$ coefficient, $Normal(0,1)$. To assess whether our chosen informative prior would bias parameter estimates (and, consequently, the interpretation of the results; @depaoli2017), we ran the same multilevel linear model with **weakly informative** priors (*intercept*: $Normal(4,4)$ ; $\beta$: $Normal(0,4)$) and **uninformative** priors (*intercept*: $Normal(4,10)$ ; $\beta$: $Normal(0,10)$). The choice of prior had negligible effects on the posterior distributions, because the influence of the prior washes out with a large amount of data [@edwards1963]. Therefore, all reported results refer to the model with informative priors.\
Since we had no prior knowledge regarding the standard deviation of participant and trials, we placed a **weakly informative prior** on these varying effects: a *t*-distribution with degrees of freedom $\nu$ = 3, location $\mu$ = 0, and scale $\sigma$ = 2, $Student(3,0,2)$.\
Models were fitted in *R* using the `brms` package [@bürkner2018], which employs the probabilistic programming language *Stan* [@carpenter2017] to implement a Markov chain Monte Carlo (MCMC) algorithm (i.e., No-U-Turn sampler; @homan2014) to estimate posterior distributions of the parameters of interest. Four MCMC chains with 4000 iterations (2000 warm-up) and no thinning were run to estimate parameters in each of the fitted models. Model convergence was assessed as follows: (*i*) visual inspection of trace plots, rank plots, and graphical posterior predictive checks [@gabry2019]; (*ii*) Gelman-Rubin $\hat{R}$ statistic [@gelman2013] -- comparing the between-chains variability to the within-chain variability -- between 1 and 1.05 [see also @Nalborczyk2019].\
Posterior distributions of the model parameters were summarized using the mean and 95% credible interval (CI). Differences between conditions were calculated by computing the difference between posterior distributions of the respective conditions.\
Statistical inference was performed using the **HDI + ROPE** decision rule [@kruschke2018]: values were accepted or rejected against a null hypothesis considering a small effect as practically equivalent to zero (Region of Practical Equivalence; *ROPE*). To mitigate the inevitable subjectivity intrinsic in arbitrarily choosing the values practically equivalent to zero, we explored a range of plausible ROPEs, from ±0.05 $\mu$*V* to ±0.5 $\mu$*V* in steps of 0.01 $\mu$*V*. If the percentage of the posterior differences within the full ROPE was smaller than 5%, the null hypothesis was rejected.

## RQ2a

We were asked to test the following:

> *RQ2a. There are effects of image novelty (i.e., between images shown for the first time/new vs. repeated/old images) within the time-range from 300--500 ms on EEG voltage at fronto-central channels.*

To address this question, for each participant and *new*/*old* condition we averaged activity in the time window between 300 - 500 ms after stimulus onset and electrodes *FC1*, *FC2*, *FCz*, i.e., electrodes strictly classified as fronto-central according to the international 10/10 electrode system [@chatrian1985].\
We fit Bayesian multilevel linear models following the procedure described in section \@ref(rq1), with the following differences in priors: (*i*) **informative priors**: $Normal(-8,2)$ on intercept, $Normal(0,1)$ on $\beta$; (*ii*) **weakly informative priors**: $Normal(-8,4)$ on intercept, $Normal(0,4)$ on $\beta$; (*iii*) **uninformative priors**: $Normal(-8,10)$ on intercept, $Normal(0,10)$ on $\beta$.\
Summaries of the posterior distributions of model parameters and statistical inference were performed as described in section \@ref(rq1).

## RQ2b and RQ2c

We were asked to test the following:

> *RQ2b. There are effects of image novelty (i.e., between images shown for the first time/new vs. repeated/old images) within the time-range from 300--500 ms on theta power at fronto-central channels.*

> *RQ2c. There are effects of image novelty (i.e., between images shown for the first time/new vs. repeated/old images) within the time-range from 300--500 ms on alpha power at posterior channels.*

To address these questions, we conducted a multilevel analysis contrasting the EEG data from trials with *old* images against trials with *new* images. At the first level (i.e., the participant level), we computed the averaged time-frequency maps for each of the two conditions. We then tested the resulting averaged maps at the second level for significant group effects using a paired-sample *t*-test. We used cluster-based permutation testing, due to its stringent control of familywise error rates [@maris2007]. Specifically, for every sample across the three channels, we quantified the experimental effect by a *t*-value. Selection of samples for inclusion in a cluster was implemented using threshold-free cluster enhancement (*TFCE*) [@smith2009]. TFCE eliminates the free parameter initial threshold value that determines which points are included in clustering by approximating a continuous integration across possible threshold values with a standard Riemann sum. We subsequently clustered selected samples in connected sets based on temporal and spectral adjacency and computed cluster-level statistics by taking the sum of the *t*-values within every cluster. Subsequently, we performed permutation testing using the Monte Carlo method (1000 permutations) to compute the significance probability of our observed effect [@maris2007] ($\alpha$ = 0.05). This analysis results in a cluster of adjacent data points across time, frequencies, and channels, which significantly differs in activity between old and new images.\
To test for differences in **theta** ($\theta$) power at fronto-central channels, we focused on the frequency range from 4 - 8 Hz and all frontocentral channels (FC1, FCz, FC2).\
To test for differences in **alpha** ($\alpha$) power at posterior channels, we focused on the frequency range from 8 - 13 Hz and all posterior channels (P7, P5, P3, P1, P2, P4, P6).

## RQ3a

We were asked to test the following:

> *RQ3a. There are effects of successful recognition of old images (i.e., a difference between old images correctly recognized as old [hits] vs. old images incorrectly judged as new [misses]) on EEG voltage at any channels, at any time.*

We followed the same analysis approach described in section \@ref(rq2b-and-rq2c) but on time-series data, comparing *old-hit*/*old-miss* conditions and including all timepoints and channels.

## RQ3b

We were asked to test the following:

> *RQ3b. There are effects of successful recognition of old images (i.e., a difference between old images correctly recognized as old [hits] vs. old images incorrectly judged as new [misses]) on spectral power, at any frequencies, at any channels, at any time.*

We followed the same analysis approach described in section \@ref(rq2b-and-rq2c), this time on *old-hit*/*old-miss* conditions and including all frequencies, timepoints, and channels.

## RQ4a

We were asked to test the following:

> *RQ4a. There are effects of subsequent memory (i.e., a difference between images that will be successfully remembered vs. forgotten on a subsequent repetition) on EEG voltage at any channels, at any time.*

We followed the same analysis approach described in section \@ref(rq3a), comparing *remembered*/*forgotten* conditions and including all timepoints and channels.

## RQ4b

We were asked to test the following:

> *RQ4b. There are effects of subsequent memory (i.e., a difference between images that will be successfully remembered vs. forgotten on a subsequent repetition) on spectral power, at any frequencies, at any channels, at any time.*

We followed the same analysis approach described in section \@ref(rq3b), this time on *remembered*/*forgotten* conditions and including all frequencies, timepoints, and channels.

# Results

## RQ1



## RQ2a

## RQ2b, RQ2c, RQ3a, RQ3b, RQ4a, RQ4b

No statistically significant clusters were identified for any of these research questions.

# Software

EEG preprocessing was carried out using `MNE-Python` *v*0.24.1 [@gramfort2013] in *Python* *v*3.9.7 [@vanrossum-2009] and *Spyder IDE* *v*5.1.5 [@raybaut2009]. Analysis, visualization, and report generation were carried out in *R* *v*4.1.3 [@R-base] and *RStudio IDE* *v*2022.02.1+461 [@R-studio]. We used the following *R* packages:

-   **data wrangling and analysis**: `here` *v*1.0.1 [@here], `Rmisc` *v*1.5 [@Rmisc], `tidyverse` *v*1.3.1 [@tidyverse] -- in particular `tibble` *v*3.1.6 [@tibble], `tidyr` *v*1.2.0 [@tidyr], `readr` *v*2.1.2 [@readr], `dplyr` *v*1.0.9 [@dplyr] --, `brms` *v*2.17.0 [@bürkner2018], `eegUtils` *v*0.7.0 [@eegUtils], `emmeans` *v*1.7.3 [@emmeans], `bayestestR` *v*0.11.5.1 [@bayestestR]

-   **visualization**: `ggplot2` *v*3.3.6 [@ggplot2], `eegUtils` *v*0.7.0 [@eegUtils], `bayesplot` *v*1.9.0 [@bayesplot], `viridis` *v*0.6.2 [@garnier2021], `tidybayes` *v*3.0.2 [@tidybayes], `patchwork` *v*1.1.1 [@patchwork]

-   **report generation**: `knitr` *v*1.39 [@knitr], `rmarkdown` *v*2.14 [@rmarkdown], `papaja` *v*0.1.0.9999 [@papaja]

# ANA COULD YOU PLEASE ADD HERE INFORMATION ABOUT MAKE AND THE R PACKAGES YOU USED FOR REPRODUCIBILITY (E.G., RETICULATE)? NO NEED TO ADD REFERENCES VIA RSTUDIO, BUT IF YOU WRITE DOWN DOIs YOU'LL MAKE MY LIFE EASIER :)

\newpage

# References

::: {#refs custom-style="Bibliography"}
:::
