@Article{gramfortMEGEEGData2013,
  title = {{{MEG}} and {{EEG}} Data Analysis with {{MNE-Python}}},
  author = {Alexandre Gramfort and Martin Luessi and Eric Larson and Denis A. Engemann and Daniel Strohmeier and Christian Brodbeck and Roman Goj and Mainak Jas and Teon Brooks and Lauri Parkkonen and Matti H{\"a}m{\"a}l{\"a}inen},
  date = {2013-12-26},
  journaltitle = {Frontiers in Neuroscience},
  shortjournal = {Front Neurosci},
  volume = {7},
  eprint = {24431986},
  eprinttype = {pmid},
  pages = {267},
  issn = {1662-4548},
  doi = {10.3389/fnins.2013.00267},
  abstract = {Magnetoencephalography and electroencephalography (M/EEG) measure the weak electromagnetic signals generated by neuronal activity in the brain. Using these signals to characterize and locate neural activation in the brain is a challenge that requires expertise in physics, signal processing, statistics, and numerical methods. As part of the MNE software suite, MNE-Python is an open-source software package that addresses this challenge by providing state-of-the-art algorithms implemented in Python that cover multiple methods of data preprocessing, source localization, statistical analysis, and estimation of functional connectivity between distributed brain regions. All algorithms and utility functions are implemented in a consistent manner with well-documented interfaces, enabling users to create M/EEG data analysis pipelines by writing Python scripts. Moreover, MNE-Python is tightly integrated with the core Python libraries for scientific comptutation (NumPy, SciPy) and visualization (matplotlib and Mayavi), as well as the greater neuroimaging ecosystem in Python via the Nibabel package. The code is provided under the new BSD license allowing code reuse, even in commercial products. Although MNE-Python has only been under heavy development for a couple of years, it has rapidly evolved with expanded analysis capabilities and pedagogical tutorials because multiple labs have collaborated during code development to help share best practices. MNE-Python also gives easy access to preprocessed datasets, helping users to get started quickly and facilitating reproducibility of methods by other researchers. Full documentation, including dozens of examples, is available at http://martinos.org/mne.},
  langid = {english},
  pmcid = {PMC3872725},
  keywords = {electroencephalography (EEG),magnetoencephalography (MEG),neuroimaging,open-source,python,software},
}
@Article{bigdely-shamloPREPPipelineStandardized2015,
  title = {The {{PREP}} Pipeline: Standardized Preprocessing for Large-Scale {{EEG}} Analysis},
  shorttitle = {The {{PREP}} Pipeline},
  author = {Nima Bigdely-Shamlo and Tim Mullen and Christian Kothe and Kyung-Min Su and Kay A. Robbins},
  date = {2015},
  journaltitle = {Frontiers in Neuroinformatics},
  shortjournal = {Front Neuroinform},
  volume = {9},
  eprint = {26150785},
  eprinttype = {pmid},
  pages = {16},
  issn = {1662-5196},
  doi = {10.3389/fninf.2015.00016},
  abstract = {The technology to collect brain imaging and physiological measures has become portable and ubiquitous, opening the possibility of large-scale analysis of real-world human imaging. By its nature, such data is large and complex, making automated processing essential. This paper shows how lack of attention to the very early stages of an EEG preprocessing pipeline can reduce the signal-to-noise ratio and introduce unwanted artifacts into the data, particularly for computations done in single precision. We demonstrate that ordinary average referencing improves the signal-to-noise ratio, but that noisy channels can contaminate the results. We also show that identification of noisy channels depends on the reference and examine the complex interaction of filtering, noisy channel identification, and referencing. We introduce a multi-stage robust referencing scheme to deal with the noisy channel-reference interaction. We propose a standardized early-stage EEG processing pipeline (PREP) and discuss the application of the pipeline to more than 600 EEG datasets. The pipeline includes an automatically generated report for each dataset processed. Users can download the PREP pipeline as a freely available MATLAB library from http://eegstudy.org/prepcode.},
  langid = {english},
  pmcid = {PMC4471356},
  keywords = {artifact,BCILAB,big data,EEG,EEGLAB,machine learning,preprocessing},
}
@Article{perrinSphericalSplinesScalp1989,
  title = {Spherical Splines for Scalp Potential and Current Density Mapping},
  author = {F. Perrin and J. Pernier and O. Bertrand and J. F. Echallier},
  date = {1989-02},
  journaltitle = {Electroencephalography and Clinical Neurophysiology},
  shortjournal = {Electroencephalogr Clin Neurophysiol},
  volume = {72},
  number = {2},
  eprint = {2464490},
  eprinttype = {pmid},
  pages = {184--187},
  issn = {0013-4694},
  doi = {10.1016/0013-4694(89)90180-6},
  abstract = {Description of mapping methods using spherical splines, both to interpolate scalp potentials (SPs), and to approximate scalp current densities (SCDs). Compared to a previously published method using thin plate splines, the advantages are a very simple derivation of the SCD approximation, faster computing times, and greater accuracy in areas with few electrodes.},
  langid = {english},
  keywords = {Computer Simulation,Electroencephalography,Electrophysiology,Humans,Scalp,Signal Processing; Computer-Assisted},
}
@Article{jasAutorejectAutomatedArtifact2017,
  title = {Autoreject: {{Automated}} Artifact Rejection for {{MEG}} and {{EEG}} Data},
  shorttitle = {Autoreject},
  author = {Mainak Jas and Denis A. Engemann and Yousra Bekhti and Federico Raimondo and Alexandre Gramfort},
  date = {2017-10-01},
  journaltitle = {NeuroImage},
  shortjournal = {Neuroimage},
  volume = {159},
  eprint = {28645840},
  eprinttype = {pmid},
  pages = {417--429},
  issn = {1095-9572},
  doi = {10.1016/j.neuroimage.2017.06.030},
  abstract = {We present an automated algorithm for unified rejection and repair of bad trials in magnetoencephalography (MEG) and electroencephalography (EEG) signals. Our method capitalizes on cross-validation in conjunction with a robust evaluation metric to estimate the optimal peak-to-peak threshold - a quantity commonly used for identifying bad trials in M/EEG. This approach is then extended to a more sophisticated algorithm which estimates this threshold for each sensor yielding trial-wise bad sensors. Depending on the number of bad sensors, the trial is then repaired by interpolation or by excluding it from subsequent analysis. All steps of the algorithm are fully automated thus lending itself to the name Autoreject. In order to assess the practical significance of the algorithm, we conducted extensive validation and comparisons with state-of-the-art methods on four public datasets containing MEG and EEG recordings from more than 200 subjects. The comparisons include purely qualitative efforts as well as quantitatively benchmarking against human supervised and semi-automated preprocessing pipelines. The algorithm allowed us to automate the preprocessing of MEG data from the Human Connectome Project (HCP) going up to the computation of the evoked responses. The automated nature of our method minimizes the burden of human inspection, hence supporting scalability and reliability demanded by data analysis in modern neuroscience.},
  langid = {english},
  pmcid = {PMC7243972},
  keywords = {Algorithms,Artifacts,Automated analysis,Brain,Brain Mapping,Cross-validation,Electroencephalogram (EEG),Electroencephalography,Human Connectome Project (HCP),Humans,Magnetoencephalography,Magnetoencephalography (MEG),Models; Neurological,Preprocessing,Signal Processing; Computer-Assisted,Statistical learning},
}
@Article{marisNonparametricStatisticalTesting2007,
  title = {Nonparametric Statistical Testing of {{EEG-}} and {{MEG-data}}},
  author = {Eric Maris and Robert Oostenveld},
  date = {2007-08-15},
  journaltitle = {Journal of Neuroscience Methods},
  shortjournal = {J Neurosci Methods},
  volume = {164},
  number = {1},
  eprint = {17517438},
  eprinttype = {pmid},
  pages = {177--190},
  issn = {0165-0270},
  doi = {10.1016/j.jneumeth.2007.03.024},
  abstract = {In this paper, we show how ElectroEncephaloGraphic (EEG) and MagnetoEncephaloGraphic (MEG) data can be analyzed statistically using nonparametric techniques. Nonparametric statistical tests offer complete freedom to the user with respect to the test statistic by means of which the experimental conditions are compared. This freedom provides a straightforward way to solve the multiple comparisons problem (MCP) and it allows to incorporate biophysically motivated constraints in the test statistic, which may drastically increase the sensitivity of the statistical test. The paper is written for two audiences: (1) empirical neuroscientists looking for the most appropriate data analysis method, and (2) methodologists interested in the theoretical concepts behind nonparametric statistical tests. For the empirical neuroscientist, a large part of the paper is written in a tutorial-like fashion, enabling neuroscientists to construct their own statistical test, maximizing the sensitivity to the expected effect. And for the methodologist, it is explained why the nonparametric test is formally correct. This means that we formulate a null hypothesis (identical probability distribution in the different experimental conditions) and show that the nonparametric test controls the false alarm rate under this null hypothesis.},
  langid = {english},
  keywords = {Brain,Brain Mapping,Data Interpretation; Statistical,Electroencephalography,Evoked Potentials,Humans,Magnetoencephalography,Signal Processing; Computer-Assisted,Statistics; Nonparametric},
}
@Article{smithThresholdfreeClusterEnhancement2009,
  title = {Threshold-Free Cluster Enhancement: Addressing Problems of Smoothing, Threshold Dependence and Localisation in Cluster Inference},
  shorttitle = {Threshold-Free Cluster Enhancement},
  author = {Stephen M. Smith and Thomas E. Nichols},
  date = {2009-01-01},
  journaltitle = {NeuroImage},
  shortjournal = {Neuroimage},
  volume = {44},
  number = {1},
  eprint = {18501637},
  eprinttype = {pmid},
  pages = {83--98},
  issn = {1095-9572},
  doi = {10.1016/j.neuroimage.2008.03.061},
  abstract = {Many image enhancement and thresholding techniques make use of spatial neighbourhood information to boost belief in extended areas of signal. The most common such approach in neuroimaging is cluster-based thresholding, which is often more sensitive than voxel-wise thresholding. However, a limitation is the need to define the initial cluster-forming threshold. This threshold is arbitrary, and yet its exact choice can have a large impact on the results, particularly at the lower (e.g., t, z {$<$} 4) cluster-forming thresholds frequently used. Furthermore, the amount of spatial pre-smoothing is also arbitrary (given that the expected signal extent is very rarely known in advance of the analysis). In the light of such problems, we propose a new method which attempts to keep the sensitivity benefits of cluster-based thresholding (and indeed the general concept of {"}clusters{"} of signal), while avoiding (or at least minimising) these problems. The method takes a raw statistic image and produces an output image in which the voxel-wise values represent the amount of cluster-like local spatial support. The method is thus referred to as {"}threshold-free cluster enhancement{"} (TFCE). We present the TFCE approach and discuss in detail ROC-based optimisation and comparisons with cluster-based and voxel-based thresholding. We find that TFCE gives generally better sensitivity than other methods over a wide range of test signal shapes and SNR values. We also show an example on a real imaging dataset, suggesting that TFCE does indeed provide not just improved sensitivity, but richer and more interpretable output than cluster-based thresholding.},
  langid = {english},
  keywords = {Algorithms,Area Under Curve,Brain Mapping,Humans,Image Enhancement,Image Processing; Computer-Assisted,ROC Curve},
}
@Article{marisNonparametricStatisticalTesting2007,
  title = {Nonparametric Statistical Testing of {{EEG-}} and {{MEG-data}}},
  author = {Eric Maris and Robert Oostenveld},
  date = {2007-08-15},
  journaltitle = {Journal of Neuroscience Methods},
  shortjournal = {J Neurosci Methods},
  volume = {164},
  number = {1},
  eprint = {17517438},
  eprinttype = {pmid},
  pages = {177--190},
  issn = {0165-0270},
  doi = {10.1016/j.jneumeth.2007.03.024},
  abstract = {In this paper, we show how ElectroEncephaloGraphic (EEG) and MagnetoEncephaloGraphic (MEG) data can be analyzed statistically using nonparametric techniques. Nonparametric statistical tests offer complete freedom to the user with respect to the test statistic by means of which the experimental conditions are compared. This freedom provides a straightforward way to solve the multiple comparisons problem (MCP) and it allows to incorporate biophysically motivated constraints in the test statistic, which may drastically increase the sensitivity of the statistical test. The paper is written for two audiences: (1) empirical neuroscientists looking for the most appropriate data analysis method, and (2) methodologists interested in the theoretical concepts behind nonparametric statistical tests. For the empirical neuroscientist, a large part of the paper is written in a tutorial-like fashion, enabling neuroscientists to construct their own statistical test, maximizing the sensitivity to the expected effect. And for the methodologist, it is explained why the nonparametric test is formally correct. This means that we formulate a null hypothesis (identical probability distribution in the different experimental conditions) and show that the nonparametric test controls the false alarm rate under this null hypothesis.},
  langid = {english},
  keywords = {Brain,Brain Mapping,Data Interpretation; Statistical,Electroencephalography,Evoked Potentials,Humans,Magnetoencephalography,Signal Processing; Computer-Assisted,Statistics; Nonparametric},
}
